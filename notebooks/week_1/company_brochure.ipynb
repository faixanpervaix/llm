{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c139058d",
   "metadata": {},
   "source": [
    "# Company Brochure\n",
    "\n",
    "Create a tool that scrap the data from the give company's url and create a summarized brochure for the company.\n",
    "- Extract data from the landing page and other relevant links\n",
    "- Use LLM to extract the relevant links, do not include the links like `Privacy Policy`, `Terms and Conditions`, and the links that have no relevant information.\n",
    "- Combine the content from each relevant link and use LLM to generate the company brochure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa6cf52c",
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'Markdown' from 'IPython' (/opt/miniconda3/envs/llms/lib/python3.11/site-packages/IPython/__init__.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mImportError\u001b[39m                               Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[14]\u001b[39m\u001b[32m, line 4\u001b[39m\n\u001b[32m      2\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mjson\u001b[39;00m\n\u001b[32m      3\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mrequests\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m4\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mIPython\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m display, Markdown\n\u001b[32m      5\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mrequests\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mexceptions\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m RequestException\n\u001b[32m      6\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mrequests\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mmodels\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Response\n",
      "\u001b[31mImportError\u001b[39m: cannot import name 'Markdown' from 'IPython' (/opt/miniconda3/envs/llms/lib/python3.11/site-packages/IPython/__init__.py)"
     ]
    }
   ],
   "source": [
    "#imports\n",
    "import json\n",
    "import requests\n",
    "from IPython.display import display, Markdown # type: ignore\n",
    "from requests.exceptions import RequestException\n",
    "from requests.models import Response\n",
    "from requests import codes\n",
    "from typing import Optional, List, Dict, Any\n",
    "from schemas.ollama.link import Link, LinksResponse\n",
    "from pydantic import ValidationError\n",
    "from bs4 import BeautifulSoup, Tag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6cd2bbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# constants\n",
    "MODEL = \"llama3.1:8b\"\n",
    "HEADERS = {\n",
    "    \"Content-Type\": \"application/json\"\n",
    "}\n",
    "OLLAMA_API = \"http://localhost:11434/api/chat\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a27ee2bf",
   "metadata": {},
   "source": [
    "#### Step 1: Prompt user to retrieve the company name and website url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce70cec6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# company_name = input(\"Enter the company name: \")\n",
    "# website_url = input(\"Enter the company's website URL: \")\n",
    "company_name = \"Faizan Pervaiz\"\n",
    "website_url = \"https://faizanpervaiz.com/\"\n",
    "\n",
    "if not company_name or not website_url:\n",
    "    raise ValueError(\"Company name and website URL cannot be empty.\")\n",
    "\n",
    "if not website_url.startswith(\"http\"):\n",
    "    raise ValueError(\"Please enter a valid URL starting with http or https.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57b8bb0d",
   "metadata": {},
   "source": [
    "#### Step 2: Create the webscrapper class that takes the url of a company's page and extract the title and content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f74d4c04",
   "metadata": {},
   "outputs": [],
   "source": [
    "class WebScraper:\n",
    "    irrelevant_tags = [\"script\", \"style\", \"img\", \"input\", \"button\"]\n",
    "    def __init__(self, url: str, irrelevant_tags: Optional[list[str]] = None):\n",
    "        self.url = url\n",
    "        self.raw_content: Optional[bytes] = None\n",
    "        self.title: Optional[str] = None\n",
    "        self.body: Optional[str] = None\n",
    "        self.links: Optional[list[str]] = None\n",
    "        if irrelevant_tags:\n",
    "            self.irrelevant_tags = irrelevant_tags\n",
    "        self._fetch_content()\n",
    "\n",
    "    def _fetch_content(self):\n",
    "        try:\n",
    "            response: Response = requests.get(self.url)\n",
    "            if response.status_code != codes.ok:\n",
    "                raise ValueError(f\"Failed to fetch content from {self.url}, status code: {response.status_code}\")\n",
    "            \n",
    "            self.raw_content = response.content\n",
    "\n",
    "            if not self.raw_content:\n",
    "                raise ValueError(f\"Website content is emtpy.\")\n",
    "\n",
    "            soup = BeautifulSoup(self.raw_content, \"html.parser\")\n",
    "            self.title = soup.title.string if soup.title and soup.title.string else \"No Title Found\"\n",
    "            if soup.body:\n",
    "                for irrelevant in soup.find_all(self.irrelevant_tags):\n",
    "                    irrelevant.decompose()\n",
    "                self.body = soup.body.get_text(separator=\"\\n\", strip=True)\n",
    "            \n",
    "            self.links = [\n",
    "                href for link in soup.find_all(\"a\", href=True)\n",
    "                if isinstance(link, Tag) and isinstance(href := link.get(\"href\"), str) and href.startswith(\"http\")\n",
    "            ]\n",
    "        except RequestException as e:\n",
    "            raise ValueError(f\"Failed to fetch content from {self.url}: {e}\")\n",
    "\n",
    "    def get_content(self) -> str:\n",
    "        \"\"\"\n",
    "        Returns the  page title and page content of the provided url\n",
    "        :return: returns the page title and page content\n",
    "        \"\"\"\n",
    "        return f\"\\nPage Title: {self.title}\\nPage Content:\\n{self.body}\"\n",
    "\n",
    "    def __repr__(self) -> str:\n",
    "        \"\"\"\n",
    "        Returns a string representation of the WebScraper instance.\n",
    "        This includes the URL being scraped.\n",
    "        :return: A string representation of the WebScraper instance.\n",
    "        \"\"\"\n",
    "        return f\"WebScraper(url={self.url})\"\n",
    "    \n",
    "    def __str__(self) -> str:\n",
    "        \"\"\"\n",
    "        Returns a user-friendly string representation of the WebScraper instance.\n",
    "        This can be used for logging or displaying information about the scraper.\n",
    "        :return: A user-friendly string representation of the WebScraper instance.\n",
    "        \"\"\"\n",
    "        return f\"WebScraper for {self.url}\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db4132cc",
   "metadata": {},
   "source": [
    "#### Step 3: Create system prompt for llama model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "648e44d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "system_prompt = f\"You are a helpful assistant to summarize the content of a company's website.\"\n",
    "system_prompt += f\"\\nYou'll be given a list of all of the links found on a company's website.\"\n",
    "system_prompt += f\"\\n Extract the relevant links from the provided list that can be used to create a professional brochure about the comapany.\"\n",
    "system_prompt += f\"\\nYou need to provide the list of all relevant link, skip links that are related to 'Privacy Policy', 'Terms and Conditions' and the ones that do not look relevant.\"\n",
    "system_prompt += f\"\\nProvide the list in the JSON format and the structure should look as follows:\\n\"\n",
    "system_prompt += \"\"\"{\n",
    "    \"links\": [\n",
    "        {\"type\": \"About Page\", \"link\": \"https://example.com/about-us\"}\n",
    "        {\"type\": \"Career Page\", \"link\": \"https://example.com/careers\"}\n",
    "    ]\n",
    "}\"\"\"\n",
    "system_prompt += f\"\\nMake sure that you include full url in the link.\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cd34696",
   "metadata": {},
   "source": [
    "#### Step 4: Create User Prompt For Llama Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "175279ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_user_prompt(website: WebScraper) -> str:\n",
    "    user_prompt = f\"Here is the list of links from a company website {website.url}\"\n",
    "    user_prompt += \"\\nPlease decide which links are relevant and skip the irrelevant links like 'Privacy Policy', 'Terms and Conditions' and so on.\"\n",
    "    user_prompt += \"\\nResponse with full URL of links and do not add the irrelevant links\"\n",
    "    user_prompt += \"\\nLinks from the website are:\\n\"\n",
    "    user_prompt += '\\n'.join(website.links or [])\n",
    "    user_prompt += \"\\n\\nYou should response in JSON format as the following structure:\\n\"\n",
    "    user_prompt += \"\"\"{\n",
    "        links: [\n",
    "            {type: \"about page\", \"link\": \"https://www.example.com/about\"},\n",
    "            {type: \"careers page\", \"link\": \"https://www.example.com/careers\"}\n",
    "        ]\n",
    "    }\"\"\"\n",
    "    return user_prompt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d11dc95c",
   "metadata": {},
   "source": [
    "#### Step 5: Instantiate `WebsiteScraper` Object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02b210e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "website = WebScraper(website_url)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77542b02",
   "metadata": {},
   "source": [
    "#### Step 6: Use Llama Model To Get Relevant Links"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24840e5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_relevant_links(website: WebScraper) -> List[Link]:\n",
    "    messages: List[Dict[str, Any]] = [\n",
    "        {\"role\": \"system\", \"content\": system_prompt},\n",
    "        {\"role\": \"user\", \"content\": get_user_prompt(website=website)}\n",
    "    ]\n",
    "    payload: Dict[str, Any] = {\n",
    "        \"model\": MODEL,\n",
    "        \"messages\": messages,\n",
    "        \"format\": LinksResponse.model_json_schema(),\n",
    "        \"stream\": False\n",
    "    }\n",
    "    response: Response = requests.post(OLLAMA_API, headers=HEADERS, json=payload)\n",
    "    if response.status_code != codes.ok:\n",
    "        raise ValueError(f\"Request to model API failed with status code {response.status_code}: {response.text}\")\n",
    "\n",
    "    content = response.json()['message']['content']\n",
    "\n",
    "    if not isinstance(content, str):\n",
    "        raise ValueError(\"Invalid Response\")\n",
    "    \n",
    "    content = json.loads(content)\n",
    "    try:\n",
    "        return LinksResponse.model_validate(content).links\n",
    "    except ValidationError as e:\n",
    "        print(\"Validation failed:\", e)\n",
    "        return []"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0847225e",
   "metadata": {},
   "source": [
    "#### Step 7: Retrieve Details From Each Relevant Link"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "427ba40c",
   "metadata": {},
   "outputs": [],
   "source": [
    "landing_page_content = \"Landing Page: \\n\"+website.get_content()\n",
    "links = get_relevant_links(website)\n",
    "complete_data = landing_page_content\n",
    "\n",
    "for item in links:\n",
    "    try:\n",
    "        web_page = WebScraper(str(item.link))\n",
    "        complete_data += \"\\n\" + item.type + \"\\n\" + web_page.get_content() + \"\\n\"\n",
    "    except Exception:\n",
    "        continue"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aae1b513",
   "metadata": {},
   "source": [
    "#### Step 8: System Prompt For Company Brochure Creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42b23929",
   "metadata": {},
   "outputs": [],
   "source": [
    "system_prompt = \"You are a helpful assistant that helps user to create a company brochure. \\\n",
    "You will be given the content from the relevant links from the company's website. \\\n",
    "You will use the content to create a company brochure about the company perspective, services, prospective custoemrs and recruits. \\\n",
    "Response in Markdown. Include company's culture, values, careers/jobs(if you have the information) and mission statement.\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57126dc9",
   "metadata": {},
   "source": [
    "#### Step 9: User Prompt For Company Brochure Creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1a2e095",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_user_prompt_for_brochure_creation(company_name: str, url: str) -> str:\n",
    "    \"\"\"Generates the prompt for creating a company brochure.\"\"\"\n",
    "    user_prompt =  f\"You are looking at the content of the company called {company_name}.\"\n",
    "    user_prompt += f\"\\n\\n Here is the content for the landing page and other relevent pages of the website {url}.\\n\"\n",
    "    user_prompt += \"\\n\\nUse this information to create the short company brochure in Markdown format.\"\n",
    "    user_prompt += complete_data\n",
    "    user_prompt = user_prompt[:20_000]\n",
    "    return user_prompt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d16288ce",
   "metadata": {},
   "source": [
    "#### Step 10: Create Company Browser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b9709c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is a collection of web pages with various content. I'll try to summarize the main points and identify any notable information.\n",
      "\n",
      "**Home Page**\n",
      "\n",
      "* The home page appears to be a news aggregator site, with articles from different categories (News, Business, Politics, Science, etc.).\n",
      "* The most recent article on the homepage is \"Rap group calls out publication for using their image\" dated July 18, 2025.\n",
      "* There are links to various social media platforms (Facebook, Pinterest) at the bottom of the page.\n",
      "\n",
      "**Category Pages**\n",
      "\n",
      "* I found two category pages: News and Science.\n",
      "* The News category appears to be a collection of articles from June 2025, with topics ranging from technology to entertainment.\n",
      "* The Science category has an article about a woman making consumer boycotts great again, dated June 17, 2025.\n",
      "\n",
      "**Article Details**\n",
      "\n",
      "* Most articles have the same structure:\n",
      "\t+ Introduction with a phrase like \"Intro text we refine our methods of responsive web design...\"\n",
      "\t+ A few sentences summarizing the article\n",
      "\t+ A \"Read more\" link to the full article (which appears to be a placeholder)\n",
      "* Many articles appear to be generated using a template, as they have similar phrases and structures.\n",
      "\n",
      "**Social Media Links**\n",
      "\n",
      "* There are links to Facebook and Pinterest at the bottom of the home page.\n",
      "* The Facebook link takes you to the main Facebook website, where you can log in or create an account.\n",
      "* The Pinterest link is a placeholder message asking you to turn on JavaScript.\n",
      "\n",
      "Let me know if you'd like me to focus on any specific aspect of these web pages!\n"
     ]
    }
   ],
   "source": [
    "def create_brochure(company_name:str, url: str):\n",
    "    \"\"\"Creates a company brochure using Llama API.\"\"\"\n",
    "    try:\n",
    "        messages: List[Dict[str, Any]] = [\n",
    "            {\"role\": \"system\", \"content\": system_prompt},\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": get_user_prompt_for_brochure_creation(\n",
    "                        company_name=company_name,\n",
    "                        url=url\n",
    "                    )\n",
    "            }\n",
    "        ]\n",
    "        payload: Dict[str, Any] = {\n",
    "            \"model\": MODEL,\n",
    "            \"messages\": messages,\n",
    "            \"stream\": False\n",
    "        }\n",
    "\n",
    "        response: Response = requests.post(OLLAMA_API, headers=HEADERS, json=payload)\n",
    "        if response.status_code != codes.ok:\n",
    "            raise ValueError(f\"Request to model API failed with status code {response.status_code}: {response.text}\")\n",
    "\n",
    "        content = response.json()['message']['content']\n",
    "        print(type(content))\n",
    "        display(Markdown(content))\n",
    "    except Exception as e:\n",
    "        raise RuntimeError(f\"Error while calling OpenAI API: {e}\")\n",
    "    \n",
    "create_brochure(company_name=company_name, url=website.url)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llms",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
